{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54037174</td>\n",
       "      <td>\"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77493077</td>\n",
       "      <td>Asking some his nationality is a Racial offenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79357270</td>\n",
       "      <td>The reader here is not going by my say so for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text  toxic  \\\n",
       "0  22256635  Nonsense?  kiss off, geek. what I said is true...      1   \n",
       "1  27450690  \"\\n\\n Please do not vandalize pages, as you di...      0   \n",
       "2  54037174  \"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the...      0   \n",
       "3  77493077  Asking some his nationality is a Racial offenc...      0   \n",
       "4  79357270  The reader here is not going by my say so for ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "comments = np.array(train['comment_text'])\n",
    "bag = count.fit_transform(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(count.vocabulary_)\n",
    "#print(bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "np.set_printoptions(precision=8)\n",
    "print(tfidf.fit_transform(count.fit_transform(comments)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# porter = PorterStemmer()\n",
    "# stop = stopwords.words('english')\n",
    "\n",
    "# def tokenizer(text):\n",
    "#     return text.split()\n",
    "# def tokenizer_porter(text):\n",
    "#     return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting begins for toxic\n",
      "fitting done\n",
      "time consumption= [6] seconds\n",
      "accuracy= 0.960\n",
      "c-v completed\n",
      "--------------------------------------------------\n",
      "fitting begins for severe_toxic\n",
      "fitting done\n",
      "time consumption= [5] seconds\n",
      "accuracy= 0.992\n",
      "c-v completed\n",
      "--------------------------------------------------\n",
      "fitting begins for obscene\n",
      "fitting done\n",
      "time consumption= [5] seconds\n",
      "accuracy= 0.977\n",
      "c-v completed\n",
      "--------------------------------------------------\n",
      "fitting begins for threat\n",
      "fitting done\n",
      "time consumption= [5] seconds\n",
      "accuracy= 0.998\n",
      "c-v completed\n",
      "--------------------------------------------------\n",
      "fitting begins for insult\n",
      "fitting done\n",
      "time consumption= [5] seconds\n",
      "accuracy= 0.973\n",
      "c-v completed\n",
      "--------------------------------------------------\n",
      "fitting begins for identity_hate\n",
      "fitting done\n",
      "time consumption= [5] seconds\n",
      "accuracy= 0.993\n",
      "c-v completed\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import os\n",
    "from time import time\n",
    "from mylib.tokenizer import tokenizer, tokenizer_porter\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "toxic_classes = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "for toxic_class in toxic_classes:\n",
    "\n",
    "    X_train = train.loc[:35000, 'comment_text'].values\n",
    "    y_train = train.loc[:35000, toxic_class].values\n",
    "    X_test = train.loc[15000:, 'comment_text'].values\n",
    "    y_test = train.loc[15000:, toxic_class].values\n",
    "\n",
    "    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "    lr_tfidf = Pipeline([('vect',tfidf),('clf',LogisticRegression(C=10.0, penalty='l2', random_state=0))])\n",
    "\n",
    "    stime = time()\n",
    "    print('fitting begins for {}'.format(toxic_class))\n",
    "    lr_tfidf.fit(X_train, y_train)\n",
    "    print('fitting done')\n",
    "\n",
    "    y_pred = lr_tfidf.predict(X_test)\n",
    "    print ('time consumption= [%d] seconds'%(time()-stime))\n",
    "    print ('accuracy= %.3f'%accuracy_score(y_test,y_pred))\n",
    "\n",
    "    print('c-v completed')\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting begins\n",
      "fitting done\n",
      "time consumption= [18] seconds\n",
      "prediction complited\n",
      "[[  9.91177650e-01   8.82234955e-03]\n",
      " [  9.96607776e-01   3.39222420e-03]\n",
      " [  9.98638965e-01   1.36103490e-03]\n",
      " ..., \n",
      " [  9.96208556e-01   3.79144389e-03]\n",
      " [  9.31948321e-01   6.80516793e-02]\n",
      " [  9.99619466e-01   3.80534442e-04]]\n",
      "classification completed\n",
      "--------------------------------------------------\n",
      "fitting begins\n",
      "fitting done\n",
      "time consumption= [18] seconds\n",
      "prediction complited\n",
      "[[  9.96129083e-01   3.87091716e-03]\n",
      " [  9.99759918e-01   2.40081617e-04]\n",
      " [  9.99675734e-01   3.24266248e-04]\n",
      " ..., \n",
      " [  9.99821956e-01   1.78043949e-04]\n",
      " [  9.96106156e-01   3.89384420e-03]\n",
      " [  9.99976129e-01   2.38707632e-05]]\n",
      "classification completed\n",
      "--------------------------------------------------\n",
      "fitting begins\n",
      "fitting done\n",
      "time consumption= [16] seconds\n",
      "prediction complited\n",
      "[[  9.82175533e-01   1.78244666e-02]\n",
      " [  9.98221626e-01   1.77837388e-03]\n",
      " [  9.98665630e-01   1.33437007e-03]\n",
      " ..., \n",
      " [  9.89707809e-01   1.02921906e-02]\n",
      " [  9.71468446e-01   2.85315542e-02]\n",
      " [  9.99474701e-01   5.25299270e-04]]\n",
      "classification completed\n",
      "--------------------------------------------------\n",
      "fitting begins\n",
      "fitting done\n",
      "time consumption= [16] seconds\n",
      "prediction complited\n",
      "[[  9.98098683e-01   1.90131704e-03]\n",
      " [  9.99808672e-01   1.91327746e-04]\n",
      " [  9.99830837e-01   1.69163060e-04]\n",
      " ..., \n",
      " [  9.99431228e-01   5.68772156e-04]\n",
      " [  9.99311045e-01   6.88954552e-04]\n",
      " [  9.99978266e-01   2.17337407e-05]]\n",
      "classification completed\n",
      "--------------------------------------------------\n",
      "fitting begins\n",
      "fitting done\n",
      "time consumption= [18] seconds\n",
      "prediction complited\n",
      "[[  9.86457368e-01   1.35426324e-02]\n",
      " [  9.99669346e-01   3.30654184e-04]\n",
      " [  9.98807405e-01   1.19259490e-03]\n",
      " ..., \n",
      " [  9.95051269e-01   4.94873071e-03]\n",
      " [  9.69002906e-01   3.09970935e-02]\n",
      " [  9.99618568e-01   3.81431756e-04]]\n",
      "classification completed\n",
      "--------------------------------------------------\n",
      "fitting begins\n",
      "fitting done\n",
      "time consumption= [17] seconds\n",
      "prediction complited\n",
      "[[  9.97689705e-01   2.31029519e-03]\n",
      " [  9.99315782e-01   6.84217788e-04]\n",
      " [  9.99698725e-01   3.01274982e-04]\n",
      " ..., \n",
      " [  9.96844632e-01   3.15536782e-03]\n",
      " [  9.96435373e-01   3.56462665e-03]\n",
      " [  9.99883231e-01   1.16769059e-04]]\n",
      "classification completed\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import os\n",
    "from time import time\n",
    "from mylib.tokenizer import tokenizer, tokenizer_porter\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test0 = pd.read_csv('test.csv')\n",
    "test = test0['comment_text'].fillna(' ')\n",
    "np.array(test)\n",
    "\n",
    "toxic_classes = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "for toxic_class in toxic_classes:\n",
    "\n",
    "    X_train = train['comment_text']\n",
    "    y_train = train[toxic_class]\n",
    "    \n",
    "\n",
    "    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "    lr_tfidf = Pipeline([('vect',tfidf),('clf',LogisticRegression(C=10.0, penalty='l2', random_state=0))])\n",
    "\n",
    "    stime = time()\n",
    "    print('fitting begins')\n",
    "    lr_tfidf.fit(X_train, y_train)\n",
    "    print('fitting done')\n",
    "\n",
    "    y_pred = lr_tfidf.predict_proba(test)\n",
    "    print ('time consumption= [%d] seconds'%(time()-stime))\n",
    "    print ('prediction complited')\n",
    "    \n",
    "    print (y_pred)\n",
    "    \n",
    "    test0['{}'.format(toxic_class)] = pd.Series(list(y_pred[:,1]))\n",
    "    \n",
    "\n",
    "    print('classification completed')\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>==Orphaned non-free media (Image:41cD1jboEvL. ...</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.017824</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.013543</td>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>::Kentuckiana is colloquial.  Even though the ...</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14563293</td>\n",
       "      <td>Hello fellow Wikipedians,\\nI have just modifie...</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21086297</td>\n",
       "      <td>AKC Suspensions \\nThe Morning Call - Feb 24, 2...</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.009122</td>\n",
       "      <td>0.002905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22982444</td>\n",
       "      <td>== [WIKI_LINK: Talk:Celts] ==</td>\n",
       "      <td>0.233255</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.060772</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.063316</td>\n",
       "      <td>0.003992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                       comment_text     toxic  \\\n",
       "0   6044863  ==Orphaned non-free media (Image:41cD1jboEvL. ...  0.008822   \n",
       "1   6102620  ::Kentuckiana is colloquial.  Even though the ...  0.003392   \n",
       "2  14563293  Hello fellow Wikipedians,\\nI have just modifie...  0.001361   \n",
       "3  21086297  AKC Suspensions \\nThe Morning Call - Feb 24, 2...  0.018333   \n",
       "4  22982444                      == [WIKI_LINK: Talk:Celts] ==  0.233255   \n",
       "\n",
       "   severe_toxic   obscene    threat    insult  identity_hate  \n",
       "0      0.003871  0.017824  0.001901  0.013543       0.002310  \n",
       "1      0.000240  0.001778  0.000191  0.000331       0.000684  \n",
       "2      0.000324  0.001334  0.000169  0.001193       0.000301  \n",
       "3      0.002446  0.007279  0.001326  0.009122       0.002905  \n",
       "4      0.005540  0.060772  0.000430  0.063316       0.003992  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del test0['comment_text']\n",
    "test0.to_csv('first_answer.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.960\n",
      "write your own comment: \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "X_train = train.loc[:35000, 'comment_text'].values\n",
    "y_train = train.loc[:35000, 'toxic'].values\n",
    "X_test = train.loc[15000:, 'comment_text'].values\n",
    "y_test = train.loc[15000:, 'toxic'].values\n",
    "\n",
    "\n",
    "curDir = os.getcwd()\n",
    "clf = pickle.load(open(os.path.join(curDir, 'data','pklObject', 'classfier.pkl'),'rb'))\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print ('accuracy= %.3f'%accuracy_score(y_test,y_pred))\n",
    "\n",
    "label = {0: 'not toxic', 1: 'toxic'}\n",
    "\n",
    "while True:\n",
    "    txt = input('write your own comment: ')\n",
    "    if txt == \"\":\n",
    "        break\n",
    "    \n",
    "    example = [txt]\n",
    "    print ('prediction= %s\\nprobability= %.3f%%'%(label[clf.predict(example)[0]],np.max(clf.predict_proba(example))*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
